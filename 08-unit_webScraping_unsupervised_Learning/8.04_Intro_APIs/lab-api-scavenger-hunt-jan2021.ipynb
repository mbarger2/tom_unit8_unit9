{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: ········\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import getpass\n",
    "\n",
    "username = '' # Enter your username here \n",
    "token = getpass.getpass(prompt='Token: ', stream=None)\n",
    "\n",
    "# Create a re-usable session object with the user creds in-built\n",
    "# Use the same token you created in class or create a new token. \n",
    "\n",
    "gh_session = requests.Session()\n",
    "gh_session.auth = (username, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Fork Languages\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Obtain the full list of forks created from the repo below via Github API.\n",
    "# Repo is rhiever/Data-Analysis-and-Machine-Learning-Projects\n",
    "# link to the repo \"https://github.com/rhiever/Data-Analysis-and-Machine-Learning-Projects\"\n",
    "url = 'https://api.github.com/repos/rhiever/Data-Analysis-and-Machine-Learning-Projects/forks'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Loop the JSON response to find out the language attribute of each fork.\n",
    "# Use an array to store the language attributes of each fork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Challenge 2: Count Commits \n",
    "\n",
    "# 1. Obtain all the commits made in the past week via API,\n",
    "# which is a JSON array that contains multiple commit objects.\n",
    "# 2. Count how many commit objects are contained in the array.\n",
    "\n",
    "# Get commits made this year, since no commits have been made since 2021\n",
    "d = '2021-01-01'\n",
    "\n",
    "# # You can find commits made for eack fork using this code \n",
    "#     commit_url = (fork['commits_url'].replace(\"{/sha}\", \"\") + '?since=' + d)\n",
    "#     commits = json.loads(gh_session.get(commit_url).text)\n",
    "\n",
    "# count the total number of commits made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scavenger Hunt "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Challenge 3 \n",
    "\n",
    "Using Python, call Github API to find out the cold joke contained in the 24 secret files in this repo whose filenames contain `.scavengerhunt`. The secret files are named from `.0001.scavengerhunt` to `.0024.scavengerhunt`. They are scattered randomly throughout this repo. You need to **search for these files by calling the Github API**, not searching on your computer.\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Github API documentation can be found [here](https://developer.github.com/v3/).\n",
    "\n",
    "* The repo you'll search under is `ironhack-datalabs/madrid-oct-2018`.\n",
    "\n",
    "* After figuring out the correct parameters, you need to inspect the JSON data structure and decide how to parse the data objects. Then you can write the Python scripts to do actual parsing. \n",
    "\n",
    "* When you test your requests to Github API, sometimes you may be blocked by Github with an error message that reads:\n",
    "\n",
    "\t```You have triggered an abuse detection mechanism and have been temporarily blocked from content creation. Please retry your request again later.```\n",
    "\n",
    "\tDon't worry. Check the parameters in your request and wait for a minute or two before you make additional requests.\n",
    "\n",
    "After you find out the secrete files: \n",
    "\n",
    "1. Order them ascendingly based on the numeric value in the filenames.\n",
    "\n",
    "1. Read the content of each secret files into an array of strings.\n",
    "\n",
    "1. Concatenate the strings in the array separating each two with a whitespace.\n",
    "\n",
    "1. Print out the joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the hints given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_url = 'https://api.github.com/repos/ironhack-datalabs/scavenger'\n",
    "url = repo_url + '/git/trees/9308ccc8a4c34c5e3a991ee815222a9691c32476?recursive=1'\n",
    "# Load the data from the url \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all file names that end in '.scavengerhunt'\n",
    "\n",
    "# Sort the data in the ascending order of the numbers used in the files. For eg. \n",
    "\n",
    "# '.0001.scavengerhunt',\n",
    "#  '.0002.scavengerhunt',\n",
    "#  '.0003.scavengerhunt',\n",
    "#  '.0004.scavengerhunt',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden Cold Joke: This is the logic that you would use \n",
    "\n",
    "# After you sort the secrete files:\n",
    "# 1. Read the content of each secret files into an array of strings.\n",
    "# 2. Concatenate the strings in the array separating each two with a whitespace.\n",
    "# 3. Print out the joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary of all paths for each file. Call it \"fpaths\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content for all needed files\n",
    "# Create an empty list \n",
    "# For each file:\n",
    "#     generate the url using:  url = repo_url + '/contents/'  + fpaths[file]\n",
    "#     load the contents of the url \n",
    "#     extract the message using: message = base64.b64decode(content['content']).decode(\"utf-8\")\n",
    "#     clean the message \n",
    "#     Append the message to a list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Concatenate the strings in the array separating each two with a whitespace.\n",
    "# 3. Print out the joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
